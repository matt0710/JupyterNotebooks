{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ad1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c48090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31018f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Conv2DTranspose, LeakyReLU, Activation, Flatten, Dense, Input, MaxPool2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, SeparableConv2D, Add, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import Sequential, losses\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbead84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ae54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class SSIMLayer(Layer):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(SSIMLayer, self).__init__()\n",
    "\n",
    "  def call(self, inputs):\n",
    "    img1, img2 = inputs\n",
    "    ssim = tf.image.ssim_multiscale(img1, img2, 1.0)\n",
    "    return ssim\n",
    "\n",
    "class AutoencoderBPR4(Model):\n",
    "  def __init__(self):\n",
    "    super(AutoencoderBPR4, self).__init__()\n",
    "    self.encoder = Sequential([\n",
    "      Input(shape=(224, 224, 1)),\n",
    "      Conv2D(32, (3, 3), activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      MaxPooling2D((2,2)),\n",
    "      Conv2D(32, (4, 4), activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      MaxPooling2D((2,2)),\n",
    "      Conv2D(32, (3, 3), activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      MaxPooling2D((1,1)),\n",
    "      Conv2D(32*2, (4, 4), activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      MaxPooling2D((2,2)),\n",
    "      Conv2D(32*2, (3, 3), activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      MaxPooling2D((1,1)),\n",
    "      Conv2D(32*4, (4, 4), activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      MaxPooling2D((2,2)),\n",
    "      Conv2D(32*2, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      MaxPooling2D((1,1)),\n",
    "      Conv2D(32, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      MaxPooling2D((1,1)),\n",
    "      Conv2D(256, (8, 8), strides=1, activation='linear', padding='valid'),\n",
    "      ])\n",
    "\n",
    "    self.decoder = Sequential([\n",
    "      Conv2DTranspose(32, (8, 8), strides=1, activation=LeakyReLU(alpha=0.2), padding='valid'),\n",
    "      Conv2D(32*2, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      Conv2D(32*4, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      Conv2DTranspose(32*2, (4, 4), strides=2, activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      Conv2D(32*2, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      Conv2DTranspose(32, (4, 4), strides=2, activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      Conv2D(32, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      Conv2DTranspose(32, (4, 4), strides=2, activation=LeakyReLU(alpha=0.2), padding='same'),\n",
    "      Conv2DTranspose(1, (4, 4), strides=2, activation='sigmoid', padding='same'),\n",
    "      ])\n",
    "    \n",
    "    self.ssim_layer = SSIMLayer()\n",
    "  \n",
    "    self.optimizer = Adam(learning_rate=1e-04)\n",
    "\n",
    "  \n",
    "  def call(self, x):\n",
    "    anchor, img_test = x\n",
    "\n",
    "    encoded_pos = self.encoder(anchor)\n",
    "    decoded_pos = self.decoder(encoded_pos)\n",
    "    ssim_pos = self.ssim_layer([anchor, decoded_pos])\n",
    "\n",
    "    encoded_neg = self.encoder(img_test)\n",
    "    decoded_neg = self.decoder(encoded_neg)\n",
    "    ssim_neg = self.ssim_layer([anchor, decoded_neg])\n",
    "\n",
    "    return ssim_pos, ssim_neg\n",
    "\n",
    "\n",
    "    \n",
    "#DEVI CALCOLARE SSIM TRA IMMAGINE CHE HO DATO COMWE NEG E LA POS\n",
    "  \n",
    "  @tf.function\n",
    "  def train_step(self, data):\n",
    "    img, neg = data\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "      ssim_pos, ssim_neg = self(data, training=True)\n",
    "      \n",
    "      difference = tf.clip_by_value(ssim_pos - ssim_neg, -1, 1)\n",
    "\n",
    "      loss = tf.reduce_sum(tf.nn.softplus(-difference))\n",
    "\n",
    "    # Compute gradients\n",
    "    trainable_vars = self.trainable_variables\n",
    "    gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "    # Update weights\n",
    "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "    return {\"loss\": loss}\n",
    "    \n",
    "\n",
    "  @tf.function\n",
    "  def test_step(self, data):\n",
    "    # Unpack the data\n",
    "    img, neg = data\n",
    "    \n",
    "    ssim_pos, ssim_neg = self(data, training=False)\n",
    "    \n",
    "    difference = tf.clip_by_value(ssim_pos - ssim_neg, -1, 1)\n",
    "    test_loss = tf.reduce_sum(tf.nn.softplus(-difference))\n",
    "\n",
    "    return {\"test loss\": test_loss}\n",
    "\n",
    "\n",
    "  @tf.function\n",
    "  def predict(self, data):\n",
    "    ssim1, ssim2 = self(data, training=False)\n",
    "    return ssim1, ssim2\n",
    "\n",
    "autoencoderBPR4 = AutoencoderBPR4()\n",
    "autoencoderBPR4.build([[None, 224, 224, 1], [None, 224, 224, 1]])\n",
    "# autoencoderBPR4.load_weights('/content/autoencoder3108_1.hdf5')\n",
    "autoencoderBPR4.load_weights('/content/autoencoderBPR4_19_09.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef65344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_mine(img_dir, img_list):\n",
    "  images = []\n",
    "  for i, img_name in enumerate(img_list):\n",
    "    if img_name.split('.')[1] == 'png':\n",
    "      t1 = time.time()\n",
    "      image = (load_img(os.path.join(img_dir, img_name), color_mode='grayscale'))\n",
    "      t2 = time.time()\n",
    "      image = img_to_array(image)\n",
    "      t3 = time.time()\n",
    "      image = np.divide(image, 255)\n",
    "      t4 = time.time()\n",
    "      image = image.astype('float32')\n",
    "      t5 = time.time()\n",
    "      #image = (img_to_array(load_img(os.path.join(img_dir, img_name), color_mode='grayscale'))/255).astype('float32')\n",
    "      images.append(image)\n",
    "      t6 = time.time()\n",
    "      # t1 = time.time()\n",
    "      # image = cv2.imread(os.path.join(img_dir, img_name), 0)\n",
    "      # t2 = time.time()\n",
    "      # image = np.divide(image, 255).astype('float32')\n",
    "      # t3 = time.time()\n",
    "      # images.append(image)\n",
    "      # t4 = time.time()\n",
    "\n",
    "      # print(f\"load image in: {t2-t1}, divided: {t3-t2}, append: {t4-t3}\")\n",
    "#       if i < 10:\n",
    "#         print(f\"load image in: {t2-t1}, img_to_array: {t3-t2}, divided: {t4-t3}, astype: {t5-t4}, append: {t6-t5}\")\n",
    "\n",
    "  return np.array(images)\n",
    "\n",
    "\n",
    "\n",
    "def dataLoaderImagesAutoencoderBPR(img_dir, img_list, gt_dir, gt_list, batch_size, random_seed=42):\n",
    "  assert len(img_list) == len(gt_list)\n",
    "  L = len(img_list)\n",
    "\n",
    "  while True:\n",
    "    batch_start = 0\n",
    "    batch_end = batch_size\n",
    "\n",
    "    while batch_start < L:\n",
    "      limit = min(batch_end, L)\n",
    "\n",
    "      if not len(img_list[batch_start:limit]) == batch_size:\n",
    "        batch_start += batch_size\n",
    "        batch_end += batch_size\n",
    "        continue\n",
    "\n",
    "      x_img = load_img_mine(img_dir, img_list[batch_start:limit])\n",
    "      y_img = load_img_mine(gt_dir, gt_list[batch_start:limit])\n",
    "\n",
    "      yield (x_img, y_img)\n",
    "\n",
    "      batch_start += batch_size\n",
    "      batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = cv2.imread('new_dataset_9000_11_08/new_colored/colored_0001_0.png')\n",
    "#Â cv2.imshow(\"ssss\",i)\n",
    "%matplotlib inline\n",
    "#The line above is necesary to show Matplotlib's plots inside a Jupyter Notebook\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7566401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def run_inference_time(img_dir, index, autoencoder_model, start_index, stop_index):\n",
    "  \n",
    "    max_tot, index_tot, count = 0, 0, 0\n",
    "\n",
    "    list_item = sorted(os.listdir(img_dir))[index]\n",
    "    im_test = (img_to_array(load_img(os.path.join(img_dir, list_item), color_mode='grayscale'))/255).astype('float32')\n",
    "\n",
    "\n",
    "    loop_list = sorted(os.listdir(img_dir))[start_index:stop_index]\n",
    "    initial = len(loop_list)\n",
    "\n",
    "    if list_item in loop_list:\n",
    "        loop_list.remove(list_item) \n",
    "\n",
    "    print(f\"list_item {list_item}, loop_list_length {initial} --> {len(loop_list)}\")\n",
    "\n",
    "    batch_size = 128\n",
    "\n",
    "    dataloader_train_bpr = dataLoaderImagesAutoencoderBPR(img_dir, loop_list, img_dir, loop_list, batch_size)\n",
    "\n",
    "    steps_per_epoch = len(loop_list) // batch_size \n",
    "\n",
    "    for i in range(steps_per_epoch):\n",
    "        t1 = time.time()\n",
    "        test_im, _ = dataloader_train_bpr.__next__()\n",
    "        t2 = time.time()\n",
    "        count += batch_size\n",
    "\n",
    "        _, ssimi = autoencoder_model.predict([np.expand_dims(im_test, 0), test_im])\n",
    "        # print(ssimi)\n",
    "        t3 = time.time()\n",
    "\n",
    "        for j, s in enumerate(ssimi):\n",
    "            if max_tot < s:\n",
    "                max_tot = s\n",
    "                # index_tot = i\n",
    "                final_im = test_im[j]\n",
    "\n",
    "        print(f\"time required for reading: {t2 - t1}, time required for inference: {t3 - t2}\")\n",
    "        print(\"_______________________________________________________________________________________________________________\")\n",
    "\n",
    "    # final_im = (img_to_array(load_img(os.path.join(img_dir, final_im), color_mode='grayscale'))/255).astype('float32')\n",
    "\n",
    "    #   plt.imshow((im_test*255).astype('uint8'))\n",
    "    #   plt.show()\n",
    "\n",
    "    #   plt.imshow((final_im*255).astype('uint8'))\n",
    "    #   plt.show()\n",
    "\n",
    "    print(max_tot)\n",
    "    print(count)\n",
    "\n",
    "\n",
    "    return im_test, final_im, max_tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "im_test, final_im, max_ssim = run_inference_time('/content/new_dataset_9000_11_08/new_colored', 1000, autoencoderBPR4)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d77d368e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 7302), (7302, 14604), (14604, 21906), (21906, 29209)]\n"
     ]
    }
   ],
   "source": [
    "N = 4\n",
    "elements = len(sorted(os.listdir('/content/new_dataset_9000_11_08/new_colored')))\n",
    "index_bound = math.floor(elements/N)\n",
    "\n",
    "index_list = []\n",
    "\n",
    "for i in range(N):\n",
    "    start = i*index_bound\n",
    "    stop = start + index_bound\n",
    "    \n",
    "    if i == (N-1):\n",
    "        stop = elements\n",
    "\n",
    "    index_list.append((start, stop))\n",
    "\n",
    "print(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e7c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting thread_1\n",
      "Starting thread_2\n",
      "Starting thread_3\n",
      "Starting thread_4\n",
      "list_item colored_3342_2.png, loop_list_length 7302 --> 7302\n",
      "list_item colored_3342_2.png, loop_list_length 7302 --> 7301\n",
      "list_item colored_3342_2.png, loop_list_length 7302 --> 7302\n",
      "list_item colored_3342_2.png, loop_list_length 7303 --> 7303\n",
      "time required for reading: 0.6837611198425293, time required for inference: 0.47168469429016113\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6767621040344238, time required for inference: 0.5504796504974365\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.643573522567749, time required for inference: 0.49993228912353516\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.7169146537780762, time required for inference: 0.4582555294036865\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6300272941589355, time required for inference: 0.48580169677734375\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6048274040222168, time required for inference: 0.5115561485290527time required for reading: 0.6521670818328857, time required for inference: 0.46733832359313965\n",
      "\n",
      "_______________________________________________________________________________________________________________\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6459898948669434, time required for inference: 0.4715733528137207\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6303589344024658, time required for inference: 0.5162358283996582\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.7148041725158691, time required for inference: 0.43102526664733887\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6419880390167236, time required for inference: 0.5027501583099365\n",
      "time required for reading: 0.7011315822601318, time required for inference: 0.44313478469848633_______________________________________________________________________________________________________________\n",
      "\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.636667013168335, time required for inference: 0.4873504638671875time required for reading: 0.6484866142272949, time required for inference: 0.47866058349609375\n",
      "_______________________________________________________________________________________________________________\n",
      "\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6120903491973877, time required for inference: 0.5171933174133301\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6173384189605713, time required for inference: 0.5091004371643066\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.625295877456665, time required for inference: 0.5068063735961914\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6199769973754883, time required for inference: 0.5166094303131104\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6342699527740479, time required for inference: 0.5004115104675293\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6364037990570068, time required for inference: 0.4985644817352295\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6201703548431396, time required for inference: 0.4999854564666748\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6308324337005615, time required for inference: 0.4854576587677002\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.5950391292572021, time required for inference: 0.5232768058776855\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6052026748657227, time required for inference: 0.5126364231109619\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6477875709533691, time required for inference: 0.4770071506500244\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6326408386230469, time required for inference: 0.49512219429016113\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6132171154022217, time required for inference: 0.5144984722137451time required for reading: 0.6821951866149902, time required for inference: 0.4423410892486572\n",
      "_______________________________________________________________________________________________________________\n",
      "_______________________________________________________________________________________________________________\n",
      "\n",
      "time required for reading: 0.6543092727661133, time required for inference: 0.49961423873901367\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6716513633728027, time required for inference: 0.4773976802825928\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6396455764770508, time required for inference: 0.5091047286987305\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6246170997619629, time required for inference: 0.5254566669464111\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6405510902404785, time required for inference: 0.5190930366516113\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6590912342071533, time required for inference: 0.49474430084228516\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6664037704467773, time required for inference: 0.4878990650177002\n",
      "_______________________________________________________________________________________________________________\n",
      "time required for reading: 0.6567566394805908, time required for inference: 0.5047409534454346\n",
      "_______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "class myThread (threading.Thread):\n",
    "    def __init__(self, indexes, name):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.indexes = indexes\n",
    "        self.name = name\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"Starting {self.name}\")\n",
    "        t1 = time.time()\n",
    "        im_test, final_im, max_ssim = run_inference_time('/content/new_dataset_9000_11_08/new_colored', 10000, autoencoderBPR4, self.indexes[0], self.indexes[1])\n",
    "        print(f\"i am in thread and this is max ssim {max_ssim}\")\n",
    "        self.im_test, self.final_im, self.max_ssim = im_test, final_im, max_ssim\n",
    "        t2 = time.time()\n",
    "        print(f\"Exiting {self.name}, time spent: {t2-t1}\")\n",
    "\n",
    "\n",
    "thread_list = []\n",
    "for t in range(N):\n",
    "    thread_list.append(myThread(index_list[t], \"thread_{}\".format(t+1)))\n",
    "\n",
    "for t in thread_list:\n",
    "    t.start()\n",
    "    \n",
    "for t in thread_list:    \n",
    "    t.join()\n",
    "            \n",
    "max_ssim = 0\n",
    "max_thread = None\n",
    "for t in thread_list:\n",
    "    if t.max_ssim > max_ssim:\n",
    "        max_ssim = t.max_ssim\n",
    "        max_thread = t\n",
    "\n",
    "in_im, fin_im = t.im_test, t.final_im\n",
    "plt.imshow((in_im*255).astype('uint8'))\n",
    "plt.show()\n",
    "plt.imshow((fin_im*255).astype('uint8'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
