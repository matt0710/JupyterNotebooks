{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 11:32:13.117352: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-03 11:32:13.297561: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-03 11:32:14.051569: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-03 11:32:14.051663: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-03 11:32:14.051673: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-03 11:32:15.754476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:32:15.767862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:32:15.770595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Conv2DTranspose, LeakyReLU, Activation, Flatten, Dense, Input, MaxPool2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, SeparableConv2D, Add, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import Sequential, losses\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "from sklearn import metrics\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "# import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import time\n",
    "import threading\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "from tensorflow.keras.layers import Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grayscale_transp_0001_0.png\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/device:GPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     30\u001b[0m     img_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 32\u001b[0m     ssim_mat \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_ssim_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [5], line 23\u001b[0m, in \u001b[0;36mcompute_ssim_matrix\u001b[0;34m(img_list, path)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m             im_2 \u001b[38;5;241m=\u001b[39m load_image(path, img_list[j])\n\u001b[0;32m---> 23\u001b[0m             ssim_mat[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssim_multiscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssim_mat\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1173'>1174</a>\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1174'>1175</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1175'>1176</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1176'>1177</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1177'>1178</a>\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1178'>1179</a>\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1179'>1180</a>\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py:4547\u001b[0m, in \u001b[0;36mssim_multiscale\u001b[0;34m(img1, img2, max_val, power_factors, filter_size, filter_sigma, k1, k2)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4540'>4541</a>\u001b[0m       imgs \u001b[39m=\u001b[39m [\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4541'>4542</a>\u001b[0m           array_ops\u001b[39m.\u001b[39mreshape(x, array_ops\u001b[39m.\u001b[39mconcat([h, t], \u001b[39m0\u001b[39m))\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4542'>4543</a>\u001b[0m           \u001b[39mfor\u001b[39;00m x, h, t \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(downscaled, heads, tails)\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4543'>4544</a>\u001b[0m       ]\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4545'>4546</a>\u001b[0m     \u001b[39m# Overwrite previous ssim value since we only need the last one.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4546'>4547</a>\u001b[0m     ssim_per_channel, cs \u001b[39m=\u001b[39m _ssim_per_channel(\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4547'>4548</a>\u001b[0m         \u001b[39m*\u001b[39;49mimgs,\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4548'>4549</a>\u001b[0m         max_val\u001b[39m=\u001b[39;49mmax_val,\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4549'>4550</a>\u001b[0m         filter_size\u001b[39m=\u001b[39;49mfilter_size,\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4550'>4551</a>\u001b[0m         filter_sigma\u001b[39m=\u001b[39;49mfilter_sigma,\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4551'>4552</a>\u001b[0m         k1\u001b[39m=\u001b[39;49mk1,\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4552'>4553</a>\u001b[0m         k2\u001b[39m=\u001b[39;49mk2)\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4553'>4554</a>\u001b[0m     mcs\u001b[39m.\u001b[39mappend(nn_ops\u001b[39m.\u001b[39mrelu(cs))\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4555'>4556</a>\u001b[0m \u001b[39m# Remove the cs score for the last scale. In the MS-SSIM calculation,\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4556'>4557</a>\u001b[0m \u001b[39m# we use the l(p) at the highest scale. l(p) * cs(p) is ssim(p).\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py:4337\u001b[0m, in \u001b[0;36m_ssim_per_channel\u001b[0;34m(img1, img2, max_val, filter_size, filter_sigma, k1, k2)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4332'>4333</a>\u001b[0m   y \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mdepthwise_conv2d(x, kernel, strides\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m], padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mVALID\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4333'>4334</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4334'>4335</a>\u001b[0m       y, array_ops\u001b[39m.\u001b[39mconcat([shape[:\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m], array_ops\u001b[39m.\u001b[39mshape(y)[\u001b[39m1\u001b[39m:]], \u001b[39m0\u001b[39m))\n\u001b[0;32m-> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4336'>4337</a>\u001b[0m luminance, cs \u001b[39m=\u001b[39m _ssim_helper(img1, img2, reducer, max_val, compensation, k1,\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4337'>4338</a>\u001b[0m                              k2)\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4339'>4340</a>\u001b[0m \u001b[39m# Average over the second and the third from the last: height, width.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4340'>4341</a>\u001b[0m axes \u001b[39m=\u001b[39m constant_op\u001b[39m.\u001b[39mconstant([\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], dtype\u001b[39m=\u001b[39mdtypes\u001b[39m.\u001b[39mint32)\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py:4229\u001b[0m, in \u001b[0;36m_ssim_helper\u001b[0;34m(x, y, reducer, max_val, compensation, k1, k2)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4225'>4226</a>\u001b[0m \u001b[39m# SSIM luminance measure is\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4226'>4227</a>\u001b[0m \u001b[39m# (2 * mu_x * mu_y + c1) / (mu_x ** 2 + mu_y ** 2 + c1).\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4227'>4228</a>\u001b[0m mean0 \u001b[39m=\u001b[39m reducer(x)\n\u001b[0;32m-> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4228'>4229</a>\u001b[0m mean1 \u001b[39m=\u001b[39m reducer(y)\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4229'>4230</a>\u001b[0m num0 \u001b[39m=\u001b[39m mean0 \u001b[39m*\u001b[39m mean1 \u001b[39m*\u001b[39m \u001b[39m2.0\u001b[39m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4230'>4231</a>\u001b[0m den0 \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39msquare(mean0) \u001b[39m+\u001b[39m math_ops\u001b[39m.\u001b[39msquare(mean1)\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py:4332\u001b[0m, in \u001b[0;36m_ssim_per_channel.<locals>.reducer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4329'>4330</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreducer\u001b[39m(x):\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4330'>4331</a>\u001b[0m   shape \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mshape(x)\n\u001b[0;32m-> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4331'>4332</a>\u001b[0m   x \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39;49mreshape(x, shape\u001b[39m=\u001b[39;49marray_ops\u001b[39m.\u001b[39;49mconcat([[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], shape[\u001b[39m-\u001b[39;49m\u001b[39m3\u001b[39;49m:]], \u001b[39m0\u001b[39;49m))\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4332'>4333</a>\u001b[0m   y \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mdepthwise_conv2d(x, kernel, strides\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m], padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mVALID\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4333'>4334</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py?line=4334'>4335</a>\u001b[0m       y, array_ops\u001b[39m.\u001b[39mconcat([shape[:\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m], array_ops\u001b[39m.\u001b[39mshape(y)[\u001b[39m1\u001b[39m:]], \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1173'>1174</a>\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1174'>1175</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1175'>1176</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1176'>1177</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1177'>1178</a>\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1178'>1179</a>\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py?line=1179'>1180</a>\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:199\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py?line=62'>63</a>\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmanip.reshape\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py?line=63'>64</a>\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m     <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py?line=64'>65</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(tensor, shape, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py?line=65'>66</a>\u001b[0m   \u001b[39mr\u001b[39m\u001b[39m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py?line=66'>67</a>\u001b[0m \n\u001b[1;32m     <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py?line=67'>68</a>\u001b[0m \u001b[39m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py?line=196'>197</a>\u001b[0m \u001b[39m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py?line=197'>198</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py?line=198'>199</a>\u001b[0m   result \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mreshape(tensor, shape, name)\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py?line=199'>200</a>\u001b[0m   tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py?line=200'>201</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:8538\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py?line=8535'>8536</a>\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py?line=8536'>8537</a>\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py?line=8537'>8538</a>\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py?line=8538'>8539</a>\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mReshape\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, tensor, shape)\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py?line=8539'>8540</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py?line=8540'>8541</a>\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ssim = tf.image.ssim_multiscale(img1, img2, 1.0)\n",
    "\n",
    "def load_image(path, im):\n",
    "    image = (load_img(os.path.join(path, \n",
    "                                im), color_mode='grayscale'))\n",
    "    image = img_to_array(image)\n",
    "    # image = np.divide(image, 255)\n",
    "    # image = image.astype('float32')\n",
    "    return np.array(image)\n",
    "\n",
    "def compute_ssim_matrix(img_list, path):\n",
    "    ssim_mat = np.zeros((len(img_list), len(img_list)))\n",
    "\n",
    "    for i in range(0, len(img_list)):\n",
    "        print(img_list[i])\n",
    "        im_1 = load_image(path, img_list[i])\n",
    "        for j in range(0, len(img_list)):\n",
    "            print(j)\n",
    "            if i == j:\n",
    "                ssim_mat[i, j] = 1\n",
    "            else:\n",
    "                im_2 = load_image(path, img_list[j])\n",
    "                ssim_mat[i, j] = tf.image.ssim_multiscale(im_1, im_2, 1.0)\n",
    "    \n",
    "    return ssim_mat\n",
    "\n",
    "\n",
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "with tf.device('/device:GPU:0'):\n",
    "    img_list = sorted(os.listdir('/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/'))\n",
    "\n",
    "    ssim_mat = compute_ssim_matrix(img_list, '/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29208, 29208)\n"
     ]
    }
   ],
   "source": [
    "print(np.zeros((len(img_list), len(img_list))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 09:35:08.246174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-02 09:35:08.248274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 09:35:08.251484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 09:35:08.253982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 09:35:08.978033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 09:35:08.979945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 09:35:08.981582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-02 09:35:08.983197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13584 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2\n",
    "M = 3\n",
    "# elements = len(sorted(os.listdir('/content/new_dataset_9000_11_08/new_colored')))\n",
    "elements = len(sorted(os.listdir('/dev/shm/new_dataset_9000_11_08_grayscale/content/new_dataset_9000_11_08_grayscale/new_colored')))\n",
    "index_bound = math.floor(elements/N)\n",
    "\n",
    "index_list = []\n",
    "\n",
    "for i in range(N):\n",
    "    start = i*index_bound\n",
    "    stop = start + index_bound\n",
    "    \n",
    "    if i == (N-1):\n",
    "        stop = elements\n",
    "\n",
    "    index_list.append((start, stop))\n",
    "\n",
    "print(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NEW\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# autoencoderBPR4 = AutoencoderBPR4()\n",
    "# autoencoderBPR4.build([[batch_size, 224, 224, 1], [batch_size, 224, 224, 1]])\n",
    "# autoencoderBPR4.load_weights('/content/autoencoderBPR4_19_09.hdf5')\n",
    "\n",
    "\n",
    "import threading\n",
    "     \n",
    "shared_queue = []\n",
    "max_ssim = 0\n",
    "max_im = None\n",
    "\n",
    "'''\n",
    "the ImageReader should create several threads that make batches of images - with the size specified in batch_size parameter - and push them in a shared queue such that Inference\n",
    "Threads can read and process them.\n",
    "    '''\n",
    "class ImageReader(threading.Thread):\n",
    "    def __init__(self, name, img_dir, comparing_img_index, indexes, batch_size):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.name = name\n",
    "        self.img_dir = img_dir\n",
    "        self.comparing_img_index = comparing_img_index\n",
    "        self.indexes = indexes\n",
    "        self.start_index = self.indexes[0]\n",
    "        self.stop_index = self.indexes[1]\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        print(f\"Starting {self.name}\")\n",
    "        t1 = time.time()\n",
    "        \n",
    "        \n",
    "        list_item = sorted(os.listdir(self.img_dir))[self.comparing_img_index]\n",
    "        im_test = (img_to_array(load_img(os.path.join(self.img_dir, list_item), color_mode='grayscale'))/255).astype('float32')\n",
    "        \n",
    "        loop_list = sorted(os.listdir(self.img_dir))[self.start_index:self.stop_index]\n",
    "        initial = len(loop_list)\n",
    "        \n",
    "        if list_item in loop_list:\n",
    "            loop_list.remove(list_item) \n",
    "            \n",
    "        dataloader_train_bpr = dataLoaderImagesAutoencoderBPR(self.img_dir, loop_list, self.img_dir, loop_list, self.batch_size)\n",
    "        steps_per_epoch = len(loop_list) // self.batch_size \n",
    "        \n",
    "        for i in range(steps_per_epoch):\n",
    "            t2 = time.time()\n",
    "            batches, _ = dataloader_train_bpr.__next__()\n",
    "            global shared_queue\n",
    "            shared_queue.append(batches)\n",
    "            t3 = time.time()\n",
    "            \n",
    "            print(f\"{self.name} added one batch of {self.batch_size} in the shared queue in {t3-t2} sec.\")\n",
    "        \n",
    "        t4 = time.time()\n",
    "        \n",
    "        print(f\"{self.name} has finished in {t4-t1}\")\n",
    "        \n",
    "        \n",
    "    \n",
    "'''\n",
    "AutoencoderInference threads take batches of images from the shared queue, make inference of them and remove the elements in queue.\n",
    "'''\n",
    "class AutoencoderInference (threading.Thread):\n",
    "    def __init__(self, name, img_dir, comparing_img_index, batch_size, autoencoder):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.name = name\n",
    "        self.img_dir = img_dir\n",
    "        self.comparing_img_index = comparing_img_index\n",
    "        self.batch_size = batch_size\n",
    "        self.autoencoder = autoencoder\n",
    "        \n",
    "    \n",
    "    def run(self):\n",
    "        print(f\"Starting {self.name}\")\n",
    "        t1 = time.time()\n",
    "        \n",
    "        list_item = sorted(os.listdir(self.img_dir))[self.comparing_img_index]\n",
    "        im_test = (img_to_array(load_img(os.path.join(self.img_dir, list_item), color_mode='grayscale'))/255).astype('float32')\n",
    "        \n",
    "        # imgs = shared_queue[:self.batch_size]\n",
    "        global shared_queue\n",
    "        global readers\n",
    "        \n",
    "        \n",
    "        while all([r.is_alive() for r in readers]):\n",
    "            if len(shared_queue) == 0:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "            \n",
    "            imgs = shared_queue[:1]\n",
    "            imgs = imgs[0]\n",
    "            # print(f\"{self.name} has read imgs of shape {len(imgs)}{imgs[0].shape}\")\n",
    "            # shared_queue = shared_queue[self.batch_size:]\n",
    "            shared_queue = shared_queue[1:]\n",
    "            # shared_queue.remove(imgs)\n",
    "\n",
    "            t2 = time.time()\n",
    "            _, ssimi = self.autoencoder.predict([imgs, np.expand_dims(im_test, 0)])\n",
    "            t3 = time.time()\n",
    "\n",
    "            # print(f\"ssimi shape {ssimi[0].shape}\")\n",
    "\n",
    "\n",
    "            print(f\"{self.name} has done inference in {t3 - t2} sec.\")\n",
    "\n",
    "            for i, s in enumerate(ssimi):\n",
    "                global max_ssim\n",
    "                # print(f\"type of s {type(s)}, {s}\")\n",
    "                if s > max_ssim:\n",
    "                    max_ssim = s\n",
    "                    global max_im\n",
    "                    # print(f\"imgs is {imgs}\")\n",
    "                    print(f\"{self.name} imgs len {len(imgs)}, i is {i}\")\n",
    "                    max_im = imgs[i]\n",
    "\n",
    "            t4 = time.time()\n",
    "        \n",
    "        print(f\"{self.name} has finished in {t4 - t1} sec.\")\n",
    "        \n",
    "                                            \n",
    "readers, inferencers = [], []\n",
    "for t in range(N):\n",
    "    readers.append(ImageReader(\"reader_{}\".format(t+1), \n",
    "                               '/dev/shm/new_dataset_9000_11_08_grayscale/content/new_dataset_9000_11_08_grayscale/new_colored', \n",
    "                                4560, \n",
    "                                index_list[t],\n",
    "                                batch_size\n",
    "                              ))\n",
    "\n",
    "for s in range(M):\n",
    "    \n",
    "    inferencers.append(AutoencoderInference(\"inference_{}\".format(s+1), '/dev/shm/new_dataset_9000_11_08_grayscale/content/new_dataset_9000_11_08_grayscale/new_colored', \n",
    "                        4560, \n",
    "                        64,\n",
    "                        autoencoderBPR4)\n",
    "                      )\n",
    "    \n",
    "\n",
    "for t in readers:\n",
    "    t.start()\n",
    "    \n",
    "\n",
    "# time.sleep(1)\n",
    "# print(f\"len of queue {len(shared_queue)}\")\n",
    "                                            \n",
    "for t in inferencers:\n",
    "    t.start()\n",
    "    \n",
    "for t in readers:    \n",
    "    t.join()\n",
    "                                            \n",
    "for t in inferencers:    \n",
    "    t.join()\n",
    "            \n",
    "in_im = (img_to_array(load_img(os.path.join(inferencers[0].img_dir, sorted(os.listdir(inferencers[0].img_dir))[inferencers[0].comparing_img_index]), color_mode='grayscale')))\n",
    "plt.imshow(in_im)\n",
    "plt.show()\n",
    "plt.imshow((max_im*255).astype('uint8'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting builder_1\n",
      "Starting builder_2\n",
      "Starting builder_3\n",
      "Starting builder_4\n",
      "Starting builder_5\n",
      "Starting builder_6\n",
      "Starting builder_8\n",
      "Starting builder_7\n",
      "Starting builder_9\n",
      "Starting builder_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread builder_9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 49, in run\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 32, in compute_ssim_matrix\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 156, in Assert\n",
      "    raise errors.InvalidArgumentError(\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: 1, 112, 112, 1\n",
      "11\n",
      "Exception in thread builder_3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 49, in run\n",
      "Exception in thread builder_10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 49, in run\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 32, in compute_ssim_matrix\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 32, in compute_ssim_matrix\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 12544 values, but the requested shape has 324 [Op:Reshape]\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 324 values, but the requested shape has 12544 [Op:Reshape]\n",
      "Exception in thread Exception in thread builder_8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "builder_1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 49, in run\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 49, in run\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 32, in compute_ssim_matrix\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 32, in compute_ssim_matrix\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__FloorMod_device_/job:localhost/replica:0/task:0/device:GPU:0}} Incompatible shapes: [2] vs. [3] [Op:FloorMod]\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__GreaterEqual_device_/job:localhost/replica:0/task:0/device:GPU:0}} Incompatible shapes: [2] vs. [3]\n",
      "\t [[{{node GreaterEqual/_5}}]] [Op:GreaterEqual]\n",
      "Exception in thread builder_6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 49, in run\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 32, in compute_ssim_matrix\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__MirrorPad_device_/job:localhost/replica:0/task:0/device:GPU:0}} The first dimension of paddings must be the rank of inputs[3,2], [1,112,112,1] [Op:MirrorPad]\n",
      "Exception in thread builder_7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 49, in run\n",
      "Exception in thread builder_4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 49, in run\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 32, in compute_ssim_matrix\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 32, in compute_ssim_matrix\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 121 values, but the requested shape has 2116 [Op:Reshape]\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 2116 values, but the requested shape has 121 [Op:Reshape]\n",
      "Exception in thread builder_2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 49, in run\n",
      "  File \"/tmp/ipykernel_7774/1131430940.py\", line 32, in compute_ssim_matrix\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__MirrorPad_device_/job:localhost/replica:0/task:0/device:GPU:0}} The first dimension of paddings must be the rank of inputs[3,2], [1,28,28,1] [Op:MirrorPad]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "builder_5 has finished in 122.28273129463196\n"
     ]
    }
   ],
   "source": [
    "# ssim_mat = np.zeros((len(img_list), len(img_list)))\n",
    "img_list = sorted(os.listdir('/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/'))\n",
    "path = '/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/'\n",
    "\n",
    "img_list = img_list[:100]\n",
    "ssim_mat = np.zeros((len(img_list), len(img_list)))\n",
    "\n",
    "def load_image(path, im):\n",
    "    image = (load_img(os.path.join(path, \n",
    "                                im), color_mode='grayscale'))\n",
    "    image = img_to_array(image)\n",
    "    # image = np.divide(image, 255)\n",
    "    # image = image.astype('float32')\n",
    "    return np.array(image)\n",
    "\n",
    "def compute_ssim_matrix(img_list, path, start_index, stop_index):\n",
    "    # ssim_mat = np.zeros((len(img_list), len(img_list)))\n",
    "    global ssim_mat\n",
    "\n",
    "    for i in range(start_index, stop_index):\n",
    "        # print(img_list[i])\n",
    "        im_1 = load_image(path, img_list[i])\n",
    "        # print(im_1.shape)\n",
    "        for j in range(0, len(img_list)):\n",
    "            # print(j)\n",
    "            if i == j:\n",
    "                ssim_mat[i, j] = 1\n",
    "            else:\n",
    "                im_2 = load_image(path, img_list[j])\n",
    "                # print(im_2.shape)\n",
    "                with tf.device('/device:GPU:0'):\n",
    "                    ssim_mat[i, j] = np.array(tf.image.ssim_multiscale(np.expand_dims(im_1, 0), np.expand_dims(im_2, 0), 255.0))\n",
    "\n",
    "\n",
    "class MatrixBuilder(threading.Thread):\n",
    "    def __init__(self, name, img_dir, img_list, indexes):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.name = name\n",
    "        self.img_dir = img_dir\n",
    "        self.img_list = img_list\n",
    "        self.start_index = indexes[0]\n",
    "        self.stop_index = indexes[1]\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        print(f\"Starting {self.name}\")\n",
    "        t1 = time.time()\n",
    "\n",
    "        compute_ssim_matrix(self.img_list, self.img_dir, self.start_index, self.stop_index)\n",
    "        \n",
    "        t2 = time.time()\n",
    "        \n",
    "        print(f\"{self.name} has finished in {t2-t1}\")\n",
    "\n",
    "\n",
    "N = 10\n",
    "\n",
    "index_bound = math.floor(len(img_list)/N)\n",
    "\n",
    "index_list = []\n",
    "\n",
    "for i in range(N):\n",
    "    start = i*index_bound\n",
    "    stop = start + index_bound\n",
    "    \n",
    "    if i == (N-1):\n",
    "        stop = len(img_list)\n",
    "\n",
    "    index_list.append((start, stop))\n",
    "\n",
    "\n",
    "matrix_builders = []\n",
    "for t in range(N):\n",
    "    matrix_builders.append(MatrixBuilder(f\"builder_{t+1}\", path, img_list, index_list[t]))\n",
    "\n",
    "for t in matrix_builders:\n",
    "    t.start()\n",
    "    \n",
    "for t in matrix_builders:    \n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         ... 0.11152816 0.09128559 0.0876879 ]\n",
      " [0.         1.         0.         ... 0.15490602 0.10704208 0.23935917]\n",
      " [0.         0.         1.         ... 0.         0.22359428 0.        ]\n",
      " ...\n",
      " [0.11152816 0.15490602 0.         ... 1.         0.18416576 0.24589823]\n",
      " [0.09128559 0.10704208 0.22359428 ... 0.18416576 1.         0.26063752]\n",
      " [0.0876879  0.23935917 0.         ... 0.24589823 0.26063752 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(ssim_mat)\n",
    "# with open('ssim_mat.npy', 'wb') as f:\n",
    "#     np.save(f, ssim_mat)\n",
    "\n",
    "ssim_mat_def = ssim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[1.         0.         0.         0.14769946 0.19159353 0.22834542\n",
      " 0.07992305 0.06644374 0.         0.09343289 0.17464422 0.23407428\n",
      " 0.         0.13412827 0.12083033 0.19385885 0.         0.12655601\n",
      " 0.20315586 0.         0.16770999 0.         0.12738536 0.0676963\n",
      " 0.         0.2235302  0.         0.17469095 0.         0.\n",
      " 0.15212394 0.         0.         0.14216502 0.19649768 0.\n",
      " 0.0985119  0.         0.         0.         0.20405896 0.23195818\n",
      " 0.09244111 0.2142893  0.         0.22987732 0.         0.\n",
      " 0.10347489 0.0924172  0.         0.         0.13120624 0.\n",
      " 0.16268696 0.23161855 0.         0.         0.09678528 0.1218698\n",
      " 0.         0.14791475 0.09571249 0.1942762  0.13676122 0.09930456\n",
      " 0.         0.         0.         0.         0.         0.21756254\n",
      " 0.         0.06917217 0.12118762 0.         0.11011674 0.08887351\n",
      " 0.09055348 0.12084308 0.14028193 0.1833994  0.         0.24142571\n",
      " 0.         0.09578396 0.         0.         0.         0.\n",
      " 0.1303015  0.         0.10751683 0.15591837 0.1321047  0.\n",
      " 0.         0.11153013 0.09128668 0.08768963]\n"
     ]
    }
   ],
   "source": [
    "path = '/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/'\n",
    "\n",
    "def load_image(path, im):\n",
    "    im_list = []\n",
    "    if len(im) == 1:\n",
    "        image = (load_img(os.path.join(path, \n",
    "                                    im), color_mode='grayscale'))\n",
    "        image = img_to_array(image)\n",
    "        return np.array(image)\n",
    "\n",
    "    for i in im:\n",
    "        # print(i)\n",
    "        image = (load_img(os.path.join(path, \n",
    "                                    i), color_mode='grayscale'))\n",
    "        image = img_to_array(image)\n",
    "        # image = np.divide(image, 255)\n",
    "        # image = image.astype('float32')\n",
    "        im_list.append(image)\n",
    "    return np.array(im_list)\n",
    "\n",
    "def load_single_image(path, im):\n",
    "    image = (load_img(os.path.join(path, \n",
    "                                    im), color_mode='grayscale'))\n",
    "    image = img_to_array(image)\n",
    "    return np.array(image)\n",
    "\n",
    "img_list = sorted(os.listdir('/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/'))\n",
    "\n",
    "# aa = load_image('/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/', img_list[0])\n",
    "bb = load_image('/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/', img_list[0:100])\n",
    "print(len(np.array(tf.image.ssim_multiscale(load_single_image(path, img_list[0]), bb, 1.0))))\n",
    "print(np.array(tf.image.ssim_multiscale(load_single_image(path, img_list[0]), bb, 255.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 08:23:53.186058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-03 08:23:53.188528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 08:23:53.191835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 08:23:53.194537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 08:23:53.763815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 08:23:53.765869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 08:23:53.767742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 08:23:53.769540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13584 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-11-03 08:23:53.791783: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5862162432 exceeds 10% of free system memory.\n",
      "2022-11-03 08:23:57.629400: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
      "2022-11-03 08:24:08.664911: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.98GiB (rounded to 5350438400)requested by op DepthwiseConv2dNative\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-11-03 08:24:08.664961: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2022-11-03 08:24:08.664972: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 10, Chunks in use: 9. 2.5KiB allocated for chunks. 2.2KiB in use in bin. 36B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.664980: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 968B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.664988: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-11-03 08:24:08.664994: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665000: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665006: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665012: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665018: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665024: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665032: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 2, Chunks in use: 2. 375.0KiB allocated for chunks. 375.0KiB in use in bin. 374.9KiB client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665039: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665044: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665051: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.63MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665057: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665063: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665068: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665074: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665080: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665086: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665092: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665099: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 4, Chunks in use: 2. 13.26GiB allocated for chunks. 10.44GiB in use in bin. 10.44GiB client-requested in use in bin.\n",
      "2022-11-03 08:24:08.665106: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 4.98GiB was 256.00MiB, Chunk State: \n",
      "2022-11-03 08:24:08.665123: I tensorflow/core/common_runtime/bfc_allocator.cc:1062]   Size: 287.86MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 4.98GiB | Requested Size: 4.98GiB | in_use: 1 | bin_num: -1\n",
      "2022-11-03 08:24:08.665131: I tensorflow/core/common_runtime/bfc_allocator.cc:1062]   Size: 2.54GiB | Requested Size: 16.17MiB | in_use: 0 | bin_num: 20, prev:   Size: 5.46GiB | Requested Size: 5.46GiB | in_use: 1 | bin_num: -1\n",
      "2022-11-03 08:24:08.665136: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 5652283392\n",
      "2022-11-03 08:24:08.665145: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fcca4000000 of size 5350438400 next 18\n",
      "2022-11-03 08:24:08.665151: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fcde2e93600 of size 301844992 next 18446744073709551615\n",
      "2022-11-03 08:24:08.665156: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 8589934592\n",
      "2022-11-03 08:24:08.665162: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fcdf6000000 of size 5862162432 next 4\n",
      "2022-11-03 08:24:08.665167: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fcf53698000 of size 2727772160 next 18446744073709551615\n",
      "2022-11-03 08:24:08.665172: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 2097152\n",
      "2022-11-03 08:24:08.665177: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb600000 of size 200704 next 1\n",
      "2022-11-03 08:24:08.665184: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb631000 of size 1280 next 2\n",
      "2022-11-03 08:24:08.665189: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb631500 of size 256 next 5\n",
      "2022-11-03 08:24:08.665194: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb631600 of size 256 next 6\n",
      "2022-11-03 08:24:08.665199: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb631700 of size 256 next 7\n",
      "2022-11-03 08:24:08.665204: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb631800 of size 256 next 9\n",
      "2022-11-03 08:24:08.665209: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb631900 of size 256 next 14\n",
      "2022-11-03 08:24:08.665214: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb631a00 of size 256 next 10\n",
      "2022-11-03 08:24:08.665218: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb631b00 of size 256 next 11\n",
      "2022-11-03 08:24:08.665223: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb631c00 of size 256 next 8\n",
      "2022-11-03 08:24:08.665228: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fd1bb631d00 of size 256 next 12\n",
      "2022-11-03 08:24:08.665233: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb631e00 of size 512 next 13\n",
      "2022-11-03 08:24:08.665239: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb632000 of size 256 next 15\n",
      "2022-11-03 08:24:08.665244: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb632100 of size 183296 next 16\n",
      "2022-11-03 08:24:08.665249: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7fd1bb65ed00 of size 512 next 19\n",
      "2022-11-03 08:24:08.665254: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7fd1bb65ef00 of size 1708288 next 18446744073709551615\n",
      "2022-11-03 08:24:08.665258: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2022-11-03 08:24:08.665266: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 9 Chunks of size 256 totalling 2.2KiB\n",
      "2022-11-03 08:24:08.665271: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 512 totalling 1.0KiB\n",
      "2022-11-03 08:24:08.665277: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-11-03 08:24:08.665283: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 183296 totalling 179.0KiB\n",
      "2022-11-03 08:24:08.665289: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 200704 totalling 196.0KiB\n",
      "2022-11-03 08:24:08.665295: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 5350438400 totalling 4.98GiB\n",
      "2022-11-03 08:24:08.665300: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 5862162432 totalling 5.46GiB\n",
      "2022-11-03 08:24:08.665306: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 10.44GiB\n",
      "2022-11-03 08:24:08.665312: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 14244315136 memory_limit_: 14244315136 available bytes: 0 curr_region_allocation_bytes_: 17179869184\n",
      "2022-11-03 08:24:08.665322: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                     14244315136\n",
      "InUse:                     11212989440\n",
      "MaxInUse:                  11212989440\n",
      "NumAllocs:                          51\n",
      "MaxAllocSize:               5862162432\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-11-03 08:24:08.665331: W tensorflow/core/common_runtime/bfc_allocator.cc:491] **************************************_******************************************__________________*\n",
      "2022-11-03 08:24:08.665363: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at conv_ops.cc:1089 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[29208,1,214,214] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__DepthwiseConv2dNative_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[29208,1,214,214] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:DepthwiseConv2dNative]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(ssim_mat)\n\u001b[0;32m---> 42\u001b[0m ssim_mat \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_ssim_in_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(ssim_mat\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(ssim_mat)\n",
      "Cell \u001b[0;32mIn [3], line 38\u001b[0m, in \u001b[0;36mevaluate_ssim_in_batch\u001b[0;34m(path, img_list)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     37\u001b[0m         im \u001b[38;5;241m=\u001b[39m load_image(path, img_list)\n\u001b[0;32m---> 38\u001b[0m     ssim_mat\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssim_multiscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_single_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(ssim_mat)\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=152'>153</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=153'>154</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=154'>155</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=7206'>7207</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=7207'>7208</a>\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=7208'>7209</a>\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__DepthwiseConv2dNative_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[29208,1,214,214] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:DepthwiseConv2dNative]"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "path = '/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/'\n",
    "img_list = sorted(os.listdir('/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/'))\n",
    "\n",
    "def load_image(path, im):\n",
    "    im_list = []\n",
    "    if len(im) == 1:\n",
    "        image = (load_img(os.path.join(path, \n",
    "                                    im), color_mode='grayscale'))\n",
    "        image = img_to_array(image)\n",
    "        return np.array(image)\n",
    "\n",
    "    for i in im:\n",
    "        # print(i)\n",
    "        image = (load_img(os.path.join(path, \n",
    "                                    i), color_mode='grayscale'))\n",
    "        image = img_to_array(image)\n",
    "        # image = np.divide(image, 255)\n",
    "        # image = image.astype('float32')\n",
    "        im_list.append(image)\n",
    "    return np.array(im_list)\n",
    "\n",
    "def load_single_image(path, im):\n",
    "    image = (load_img(os.path.join(path, \n",
    "                                    im), color_mode='grayscale'))\n",
    "    image = img_to_array(image)\n",
    "    return np.array(image)\n",
    "\n",
    "\n",
    "def evaluate_ssim_in_batch(path, img_list):\n",
    "    ssim_mat = []\n",
    "    for i, im in enumerate(img_list):\n",
    "        if i==0:\n",
    "            im = load_image(path, img_list)\n",
    "        ssim_mat.append(tf.image.ssim_multiscale(load_single_image(path, img_list[i]), im, 255.0))\n",
    "        print(i)\n",
    "    return np.array(ssim_mat)\n",
    "\n",
    "ssim_mat = evaluate_ssim_in_batch(path, img_list)\n",
    "print(ssim_mat.shape)\n",
    "print(ssim_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03/11/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 11:06:39.312172: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-03 11:06:39.314486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:06:39.317891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:06:39.320517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:06:39.893700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:06:39.895760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:06:39.897440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:06:39.899084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13584 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-11-03 11:06:40.843875: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     78\u001b[0m img_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 79\u001b[0m ssim_mat \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_ssim_in_batch_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [2], line 66\u001b[0m, in \u001b[0;36mevaluate_ssim_in_batch_2\u001b[0;34m(path, img_list, ssim_mat_batch)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m ssim_index_list:\n\u001b[1;32m     65\u001b[0m     start, stop \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 66\u001b[0m     img_list_batch \u001b[38;5;241m=\u001b[39m \u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     batch_ssim_list\u001b[38;5;241m.\u001b[39mappend(tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mssim_multiscale(load_single_image(path, img_list[i]), img_list_batch, \u001b[38;5;241m255.0\u001b[39m))\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m img_list_batch\n",
      "Cell \u001b[0;32mIn [2], line 45\u001b[0m, in \u001b[0;36mload_image\u001b[0;34m(path, im)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m im:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# print(i)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     image \u001b[38;5;241m=\u001b[39m (load_img(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \n\u001b[1;32m     44\u001b[0m                                 i), color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 45\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mimg_to_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# image = np.divide(image, 255)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# image = image.astype('float32')\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     im_list\u001b[38;5;241m.\u001b[39mappend(image)\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/keras/utils/image_utils.py:324\u001b[0m, in \u001b[0;36mimg_to_array\u001b[0;34m(img, data_format, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/keras/utils/image_utils.py?line=319'>320</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown data_format: \u001b[39m\u001b[39m{\u001b[39;00mdata_format\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/keras/utils/image_utils.py?line=320'>321</a>\u001b[0m \u001b[39m# Numpy array x has format (height, width, channel)\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/keras/utils/image_utils.py?line=321'>322</a>\u001b[0m \u001b[39m# or (channel, height, width)\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/keras/utils/image_utils.py?line=322'>323</a>\u001b[0m \u001b[39m# but original PIL image has format (width, height, channel)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/keras/utils/image_utils.py?line=323'>324</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(img, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/keras/utils/image_utils.py?line=324'>325</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/keras/utils/image_utils.py?line=325'>326</a>\u001b[0m     \u001b[39mif\u001b[39;00m data_format \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mchannels_first\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/Image.py:687\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/Image.py?line=684'>685</a>\u001b[0m     new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtobytes(\u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/Image.py?line=685'>686</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/Image.py?line=686'>687</a>\u001b[0m     new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtobytes()\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/Image.py?line=687'>688</a>\u001b[0m \u001b[39mreturn\u001b[39;00m new\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/Image.py:729\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/Image.py?line=725'>726</a>\u001b[0m \u001b[39mif\u001b[39;00m encoder_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m args \u001b[39m==\u001b[39m ():\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/Image.py?line=726'>727</a>\u001b[0m     args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m--> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/Image.py?line=728'>729</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/Image.py?line=730'>731</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheight \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/Image.py?line=731'>732</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/ImageFile.py:257\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/ImageFile.py?line=250'>251</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/ImageFile.py?line=251'>252</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/ImageFile.py?line=252'>253</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/ImageFile.py?line=253'>254</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/ImageFile.py?line=255'>256</a>\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/ImageFile.py?line=256'>257</a>\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/ImageFile.py?line=257'>258</a>\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/site-packages/PIL/ImageFile.py?line=258'>259</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# np.concatenate(index_list).ravel()\n",
    "\n",
    "def evaluate_ssim_in_batch(path, img_list):\n",
    "    ssim_mat = []\n",
    "    img = load_image(path, img_list)\n",
    "    print('CARICATO')\n",
    "    for i, im in enumerate(img_list):\n",
    "        # if i==0:\n",
    "        #     im = load_image(path, img_list)\n",
    "        ssim = tf.image.ssim_multiscale(img[i], img, 255.0)\n",
    "        ssim_mat.append(ssim)\n",
    "        del ssim\n",
    "        print(f\"iterazione {i} con calcolo ssim\")\n",
    "    return np.array(ssim_mat)\n",
    "\n",
    "\n",
    "def evaluate_ssim_batch_len(img_list, ssim_mat_batch):\n",
    "    ssim_mat_bound = math.floor(len(img_list)/ssim_mat_batch)\n",
    "\n",
    "    ssim_index_list = []\n",
    "\n",
    "    for i in range(ssim_mat_batch):\n",
    "        start = i*ssim_mat_bound\n",
    "        stop = start + ssim_mat_bound\n",
    "        \n",
    "        if i == (ssim_mat_batch-1):\n",
    "            stop = len(img_list)\n",
    "\n",
    "        ssim_index_list.append((start, stop))\n",
    "\n",
    "    return ssim_index_list\n",
    "\n",
    "def load_image(path, im):\n",
    "    im_list = []\n",
    "    if len(im) == 1:\n",
    "        image = (load_img(os.path.join(path, \n",
    "                                    im), color_mode='grayscale'))\n",
    "        image = img_to_array(image)\n",
    "        return np.array(image)\n",
    "\n",
    "    for i in im:\n",
    "        # print(i)\n",
    "        image = (load_img(os.path.join(path, \n",
    "                                    i), color_mode='grayscale'))\n",
    "        image = img_to_array(image)\n",
    "        # image = np.divide(image, 255)\n",
    "        # image = image.astype('float32')\n",
    "        im_list.append(image)\n",
    "    return np.array(im_list)\n",
    "\n",
    "def load_single_image(path, im):\n",
    "    image = (load_img(os.path.join(path, \n",
    "                                    im), color_mode='grayscale'))\n",
    "    image = img_to_array(image)\n",
    "    return np.array(image)\n",
    "\n",
    "\n",
    "def evaluate_ssim_in_batch_2(path, img_list, ssim_mat_batch):\n",
    "    ssim_mat = []\n",
    "    ssim_index_list = evaluate_ssim_batch_len(img_list, ssim_mat_batch)\n",
    "\n",
    "    for i, im in enumerate(img_list):\n",
    "        batch_ssim_list = []\n",
    "        for batch in ssim_index_list:\n",
    "            start, stop = batch\n",
    "            img_list_batch = load_image(path, img_list[start:stop])\n",
    "            batch_ssim_list.append(tf.image.ssim_multiscale(load_single_image(path, img_list[i]), img_list_batch, 255.0))\n",
    "            del img_list_batch\n",
    "        \n",
    "        ssim_mat.append(np.concatenate(batch_ssim_list).ravel())\n",
    "        print(i)\n",
    "\n",
    "    return np.array(ssim_mat)\n",
    "\n",
    "\n",
    "\n",
    "path = '/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/'\n",
    "img_list = sorted(os.listdir('/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/'))\n",
    "ssim_mat = evaluate_ssim_in_batch_2(path, img_list, 10)\n",
    "# ssim_mat = evaluate_ssim_in_batch(path, img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2920)\n",
      "Starting builder_1\n",
      "Starting builder_2\n",
      "Starting builder_3\n",
      "Starting builder_4\n",
      "Starting builder_5\n",
      "Starting builder_6\n",
      "Starting builder_7\n",
      "Starting builder_8\n",
      "Starting builder_9\n",
      "Starting builder_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 11:32:22.462058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-03 11:32:22.464111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:32:22.467400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:32:22.470004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:32:23.197733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:32:23.199718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:32:23.201536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 11:32:23.203225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13584 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "Exception in thread builder_7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 76, in run\n",
      "2022-11-03 11:32:23.477797: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: Expected begin, end, and strides to be 1D equal size tensors, but got shapes [1], [3], and [1] instead.\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 51, in evaluate_ssim_in_batch_3\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} Expected begin, end, and strides to be 1D equal size tensors, but got shapes [1], [3], and [1] instead. [Op:StridedSlice] name: strided_slice/\n",
      "2022-11-03 11:32:24.348358: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
      "Exception in thread builder_2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 76, in run\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 51, in evaluate_ssim_in_batch_3\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__FloorMod_device_/job:localhost/replica:0/task:0/device:GPU:0}} Incompatible shapes: [2] vs. [3] [Op:FloorMod]\n",
      "Exception in thread builder_8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 76, in run\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 51, in evaluate_ssim_in_batch_3\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 156, in Assert\n",
      "    raise errors.InvalidArgumentError(\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: 456, 14, 14, 1\n",
      "11\n",
      "Exception in thread builder_1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 76, in run\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 51, in evaluate_ssim_in_batch_3\n",
      "Exception in thread builder_6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 76, in run\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 51, in evaluate_ssim_in_batch_3\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1068, in __bool__\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    return bool(self._numpy())\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 156, in Assert\n",
      "    raise errors.InvalidArgumentError(\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: 456, 224, 224, 1\n",
      "11\n",
      "Exception in thread builder_10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 76, in run\n",
      "Exception in thread builder_4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 76, in run\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 51, in evaluate_ssim_in_batch_3\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 51, in evaluate_ssim_in_batch_3\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} sizes input must be 1-D, not [2,1] [Op:Reshape]\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} The first dimension of paddings must be the rank of inputs[2,2] [2] [Op:Pad]\n",
      "Exception in thread builder_9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "Exception in thread builder_3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 76, in run\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 76, in run\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 51, in evaluate_ssim_in_batch_3\n",
      "  File \"/tmp/ipykernel_19337/4100642972.py\", line 51, in evaluate_ssim_in_batch_3\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/envs/matteovenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 7209, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__NotEqual_device_/job:localhost/replica:0/task:0/device:GPU:0}} Integer division by zero\n",
      "\t [[{{node NotEqual/_5}}]] [Op:NotEqual]\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__FloorMod_device_/job:localhost/replica:0/task:0/device:GPU:0}} Integer division by zero [Op:FloorMod]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m     t\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m matrix_builders:    \n\u001b[0;32m---> 99\u001b[0m     \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/threading.py?line=1056'>1057</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/threading.py?line=1058'>1059</a>\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/threading.py?line=1059'>1060</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/threading.py?line=1060'>1061</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/threading.py?line=1061'>1062</a>\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/threading.py?line=1062'>1063</a>\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/threading.py?line=1063'>1064</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/envs/matteovenv/lib/python3.9/threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/threading.py?line=1076'>1077</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/threading.py?line=1078'>1079</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/threading.py?line=1079'>1080</a>\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/threading.py?line=1080'>1081</a>\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   <a href='file:///opt/conda/envs/matteovenv/lib/python3.9/threading.py?line=1081'>1082</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate_ssim_batch_len(img_list, ssim_mat_batch):\n",
    "    ssim_mat_bound = math.floor(len(img_list)/ssim_mat_batch)\n",
    "\n",
    "    ssim_index_list = []\n",
    "\n",
    "    for i in range(ssim_mat_batch):\n",
    "        start = i*ssim_mat_bound\n",
    "        stop = start + ssim_mat_bound\n",
    "        \n",
    "        if i == (ssim_mat_batch-1):\n",
    "            stop = len(img_list)\n",
    "\n",
    "        ssim_index_list.append((start, stop))\n",
    "\n",
    "    return ssim_index_list\n",
    "\n",
    "def load_image(path, im):\n",
    "    im_list = []\n",
    "    if len(im) == 1:\n",
    "        image = (load_img(os.path.join(path, \n",
    "                                    im), color_mode='grayscale'))\n",
    "        image = img_to_array(image)\n",
    "        return np.array(image)\n",
    "\n",
    "    for i in im:\n",
    "        # print(i)\n",
    "        image = (load_img(os.path.join(path, \n",
    "                                    i), color_mode='grayscale'))\n",
    "        image = img_to_array(image)\n",
    "        # image = np.divide(image, 255)\n",
    "        # image = image.astype('float32')\n",
    "        im_list.append(image)\n",
    "    return np.array(im_list)\n",
    "\n",
    "def load_single_image(path, im):\n",
    "    image = (load_img(os.path.join(path, \n",
    "                                    im), color_mode='grayscale'))\n",
    "    image = img_to_array(image)\n",
    "    return np.array(image)\n",
    "\n",
    "def evaluate_ssim_in_batch_3(path, img_list, ssim_mat_batch, indexes):\n",
    "    ssim_mat = []\n",
    "    ssim_index_list = evaluate_ssim_batch_len(img_list, ssim_mat_batch)\n",
    "    start, stop = indexes\n",
    "\n",
    "    for i, im in enumerate(img_list[start:stop]):\n",
    "        batch_ssim_list = []\n",
    "        for batch in ssim_index_list:\n",
    "            start, stop = batch\n",
    "            img_list_batch = load_image(path, img_list[start:stop])\n",
    "            batch_ssim_list.append(tf.image.ssim_multiscale(load_single_image(path, img_list[i]), img_list_batch, 255.0))\n",
    "            del img_list_batch\n",
    "        \n",
    "        ssim_mat.append(np.concatenate(batch_ssim_list).ravel())\n",
    "        print(i)\n",
    "\n",
    "    return np.array(ssim_mat)\n",
    "\n",
    "\n",
    "class MatrixBuilder(threading.Thread):\n",
    "    def __init__(self, name, img_dir, img_list, ssim_mat_batch, indexes):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.name = name\n",
    "        self.img_dir = img_dir\n",
    "        self.img_list = img_list\n",
    "        self.ssim_mat_batch = ssim_mat_batch\n",
    "        self.indexes = indexes\n",
    "        self.start_index = indexes[0]\n",
    "        self.stop_index = indexes[1]\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        print(f\"Starting {self.name}\")\n",
    "        t1 = time.time()\n",
    "\n",
    "        evaluate_ssim_in_batch_3(self.img_dir, self.img_list, self.ssim_mat_batch, self.indexes)\n",
    "        \n",
    "        t2 = time.time()\n",
    "        \n",
    "        print(f\"{self.name} has finished in {t2-t1}\")\n",
    "\n",
    "\n",
    "\n",
    "N = 10\n",
    "path = '/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/'\n",
    "img_list = sorted(os.listdir('/dev/shm/new_dataset_9000_11_08_grayscale_transparent/content/new_dataset_9000_11_08_grayscale_transparent/new_transparent/'))\n",
    "index_list = evaluate_ssim_batch_len(img_list, N)\n",
    "matrix_builders = []\n",
    "\n",
    "print(index_list[0])\n",
    "\n",
    "for t in range(N):\n",
    "    matrix_builders.append(MatrixBuilder(f\"builder_{t+1}\", path, img_list, 64, index_list[t]))\n",
    "\n",
    "for t in matrix_builders:\n",
    "    t.start()\n",
    "    \n",
    "for t in matrix_builders:    \n",
    "    t.join()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29370cec3471073fd8647338683aadc84bf7e7c78c103de68f294f19ec9b3b41"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('matteovenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
